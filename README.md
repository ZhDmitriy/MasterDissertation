**"Миграция on-premies инфраструктуры анализа больших данных в высокомашстабируемые облачные системы на рынке образовательных услуг"**

Реализация аналитического решения на основе теории анализа больших данных по методологии Medallion Architecture, где Silver Layer будет реализован по методологии Data Vault, а Gold Layer по методологии Dimensional Modeling. Данные будут взяты из открытых API. 

**Целью работы** является создание инструмента по миграции типового аналитического on-premise решения анализа больших данных на рынке образования в высокомасштабируемые облачные системы.  

**Задачи**: 
1.	Исследовать различные подходы к реализации аналитических решений на образовательном рынке. 
2.	Определить и реализовать подходящую on-premise архитектуру хранилища данных для образовательных организаций. 
3.	Рассмотреть различные стратегии миграции аналитических решений в облако. 
4.	Реализовать инструмент по миграции DWH в облако, сравнить по оптимальности с существующими подходами.  

#Архитектура аналитической системы. Выработка требований.

**Medallion Architecture** 
![MA2](https://github.com/user-attachments/assets/4022e7cc-5de0-42c3-9685-c4bd7181716c)

**Бизнес требования**: 
1. Использовать API социальных сетей и образрвательных платформ в качестве источников данных для пользовательской аналитики:
* VK API: https://dev.vk.com/ru
* Tik Tok API: https://developers.tiktok.com/doc/tiktok-api-v2-introduction/
* Udemy API: https://www.udemy.com/developers
2. Система должна помочь исследователям проводить аналитику на рынке образования, формировать типовые аналитические отчеты для образотвального рынка и поиска инсайтов.

**Функциональные требования**: 
1. Спроектировать витрины данных для 2 и более типовых аналитических отчетов
2. Витрины данных должны поддерживать версионирование данных по SCD2, 3 или 4
3. Витрины данных (и Gold Layer соответственно) должны быть спроектированы по методологии Dimensional Modeling (Схема "Звезда")
4. Из-за возможных быстрых измнений в API, Silver Layer должен быть проектирован по методологии Data Vault
5. Bronze Layer должен быть спроектирован по 2 нормальной форме с максимально денормализованными таблицами, но с поддержкой согласованности между ними
6. Аналитические отчеты должны быть спроектированы в BI системе Yandex DataLens
7. Для реализации ETL процессов должен использоваться язык программирования Python и фреймворк Apache Spark. Инструменты dbt для трансформации данных, Dagster для оркестрации ETL процессов
8. Система должна быть гибкой и уметь перезапускаться за любой выбранный период времени, те данные можно было бы восстановить за любой отрезок времени
9. Система должна применять практики Data Quality через, например, библиотеку pedeque
10. Пользователи отчетов должны будут самостоятельно выбрать нужные измерения для своего типового отчета

**Нефункциональные требования**: 
1. Система должна быть готова к масштабированию до большого объема данных
2. Система должна быть легко обслуживаемой для специалистов по работе с данными
3. Система должна автоматически реализовывать резервное копирование. И отправлять его в любое S3 хранилище
4. Система должна обеспечивать качество данных и реализацию практик Data Governance

**Технологический стек проекта**: Dagster, dbt, Python, SQL, Greenplum, Apache Spark 
